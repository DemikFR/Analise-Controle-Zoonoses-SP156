<!-- PROJECT LOGO -->
<br />
<div align="center">
  <h1 align="center">An√°lise do Controle de Zooneses do SP156</h1>

  <p align="center">
    An√°lise dos Dados do portal SP156 da Prefeitura de SP com Power BI
  </p>
  <p align="center">
    Os dados usados se encontram na base de <a href="http://dados.prefeitura.sp.gov.br/dataset/dados-do-sp156">dados abertos da Prefeitura de SP</a>.
  </p>
  <h3 align=center>üî®Projeto ainda em desenvolvimento.üî®</h3><br>
</div>


<!-- TABLE OF CONTENTS -->
<details>
  <summary>Sum√°rio</summary>
  <ol>
    <li>
      <a href="#sobre-o-projeto">Sobre o Projeto</a>
      <ul>
        <li><a href="#ferramentas">Ferramentas</a></li>
      </ul>
    </li>
    <li><a href="#iniciar-o-projeto">Iniciar o Projeto</a></li>
    <li><a href="#requisitos-de-neg√≥cios">Requisitos de Neg√≥cios</a></li>
    <li>
      <a href="#extra√ß√£o-e-pr√©-processamento">Extra√ß√£o e Pr√©-processamento</a>
      <ul>
        <li><a href="#extra√ß√£o-web-scraping">Extra√ß√£o (Web Scraping)</a></li>
        <li><a href="#pr√©-processamento">Pr√©-processamento</a></li>
        <li><a href="#armazenamento-dos-dados">Armazenamento dos Dados</a></li>
        <li><a href="#considera√ß√µes-finais-do-processamento">Considera√ß√µes Finais do Processamento</a></li>
      </ul>  
    </li>
    <li><a href="#license">License</a></li>
    <li><a href="#contact">Contact</a></li>
  </ol>
</details>



<!-- Sobre o Projeto -->
## Sobre o Projeto

A finalidade do uso dos dados √© realizar an√°lises de dados para identificar problemas de efici√™ncia nos servi√ßos de controle de zooneses prestados pela Prefeitura de S√£o Paulo aos cidad√£os, com o objetivo de promover a transpar√™ncia, melhorar a qualidade dos servi√ßos e otimizar os recursos p√∫blicos. Al√©m disso, os dados ser√£o utilizados para fins de aprimoramento pessoal em an√°lise de dados, visando ao desenvolvimento profissional.

Para ser feita esta an√°lise, foi necess√°rio um processo de web scraping para automatizar a extra√ß√£o dos datasets, pois eles est√£o separados por datas e per√≠odos de ano em cada p√°gina diferente, depois foi feito um processo ETL para adequa√ß√£o aos requisitos de neg√≥cios, antes de salvar os dados.



### Ferramentas

Para realizar este projeto, foi usado as seguintes ferramenta:


* [![Python][Python.py]][Python-url]
* [![Power-BI][Power-BI.pbix]][Power-BI-url]



<!-- Iniciar o Projeto -->
## Iniciar o Projeto

1. Clone este Reposit√≥rio
   ```sh
   git clone https://github.com/DemikFR/Analise-Controle-Zoonoses-SP156.git
   ```
   
2. Instale as bibliotecas que ser√£o usadas no projeto
   ```py
   pip install requests
   pip install BeautifulSoup
   pip install pandas
   pip install StringIO
   pip install chardet
   ```

3. Busque o link de download da base dados da Prefeitura de SP para ser usado conforme o script Request do "data_scraping" de Python.



## Requisitos de Neg√≥cios

Como mencionado anteriormente, o objetivo deste projeto √© identificar os principais pontos de melhoria nos servi√ßos prestados e os problemas que afetam a popula√ß√£o de S√£o Paulo, no caso, com base no per√≠odo de 2012 ao √∫ltimo m√™s de 2022. Com base nisso, faremos algumas perguntas:

* Quais foram os maiores problemas?

* Em rela√ß√£o aos servi√ßos prestados, quais foram os que tiveram mais casos?

* Quais distritos tiveram mais den√∫ncias?

* Qual a quantidade de den√∫ncias recebidas por ano?

* Qual a grandeza de den√∫ncias de "Animais que transmitem doen√ßas" e quais foram os casos que tiveram mais den√∫ncias?

* Quais foram os distritos que mais tiveram den√∫ncias de "Animais que transmitem doen√ßas"?

* Quantos servi√ßos foram finalizados ou n√£o?

* No geral, √© poss√≠vel determinar se o servi√ßo prestado pela Prefeitura de S√£o Paulo √© eficiente?

Com essas perguntas, j√° ser√° poss√≠vel mapear todo o processo de an√°lise, incluindo o tratamento dos dados.



## Extra√ß√£o e Pr√©-processamento

Os dados fornecidos pela Prefeitura est√£o organizados em p√°ginas separadas para cada trimestre e ano, tanto na interface do usu√°rio como na API. Para simplificar o processo de extra√ß√£o, foi desenvolvido um script em Python que ser√° explicado detalhadamente a seguir. Esse script utiliza as bibliotecas Requests, Beautiful Soup, Pandas (incluindo StringIO) e chardet para concatenar os dados em um √∫nico conjunto de dados. Em seguida, os dados passam por um processo de transforma√ß√£o para atender aos requisitos de neg√≥cios, reduzindo seu tamanho e otimizando o processamento no Power BI.

### Extra√ß√£o (Web Scraping)

Ap√≥s ter estudado a estrutura HTML do site da Prefeitura, foi criada uma fun√ß√£o para encontrar a tag <code>&lt;a&gt;</code> a partir de um padr√£o de texto no atributo "title" do HTML.

   ```py
   def get_soup(url, search):
       response = requests.get(url)
    
       # Verificar se a conex√£o foi bem sucedida
       if response.status_code == 200:
           soup = bs(response.content, 'html.parser')

           # Retornar as p√°ginas onde ter√£o as de download
           return soup.find_all('a', href=True, attrs={'title': re.compile(search)}) 
       else:
           return f'P√°gina{link["title"]} est√° inacess√≠vel. C√≥digo: {response.status_code}'
   ```
   
A fun√ß√£o recebe dois par√¢metros: o primeiro √© a URL na qual deve-se procurar a tag e o segundo √© o padr√£o de texto que deve ser usado para localizar a tag. √â importante ressaltar que o texto fornecido deve ser uma express√£o regular (regex).

Ap√≥s a cria√ß√£o do processo anterior, agora √© poss√≠vel implementar o web scraping. Para isso, foi desenvolvido um loop for que chama a fun√ß√£o criada anteriormente e percorre a lista de links retornada por ela. Para cada link encontrado, √© feita uma nova busca para localizar o link de download do conjunto de dados na segunda p√°gina. Nesse caso, todos os links que possuem a extens√£o .csv s√£o considerados.

   ```py
   # URL base do site da Prefeitura
   url_base = 'http://dados.prefeitura.sp.gov.br'
   
   # URL inicial onde estar√£o os links para os datasets
   url_inicial = 'http://dados.prefeitura.sp.gov.br/dataset/dados-do-sp156'
   
   # extens√£o do dataset para filtrar
   file_type = '.csv'
   
   for link in get_soup(url_inicial, r'^Dados do SP156 -.*'):
       
       # Pegar o link de download
       for page in get_soup(url_base+link['href'], r'^http://dados.prefeitura.sp.gov.br/dataset/.*'):
           link_download = page['href']
           
           # Verificar se √© o arquivo a ser baixado √© Excel
           if file_type in link_download:
               
               # Pegar o conte√∫do do CSV
               response_csv = requests.get(page['href'])
               
               # Cada datset tem um encoding diferente, por isso foi necess√°rio usar a biblioteca chardet para identificar 
               # automaticamente qual √©.
               encoding = chardet.detect(response_csv.content)['encoding']
               
               # Colocar os dados na tabela auxiliar
               if int(link["title"][-4:]) >= 2020:
                   df3 = pd.read_csv(StringIO(response_csv.content.decode(encoding)), sep=';', encoding=encoding, low_memory=False)
               else:
                   df3 = pd.read_csv(StringIO(response_csv.content.decode(encoding)), sep=',', encoding=encoding, low_memory=False)
                   
               dfs.append(df3)  # Adicionar o DataFrame intermedi√°rio √† lista
               
               # Inserir os dados na planilha original
               print(f'Os dados do {link["title"]} foram inseridos com sucesso.')
   ```
  
Para extrair os dados do arquivo CSV, foi utilizado o m√©todo "get" da biblioteca Requests. O conte√∫do √© armazenado em uma vari√°vel para uso posterior.

Com o conte√∫do do conjunto de dados, √© poss√≠vel utiliz√°-lo no chardet para detectar a codifica√ß√£o (encoding) apropriada. Isso ocorre porque os conjuntos de dados podem variar em sua codifica√ß√£o, alguns est√£o em Latin1 e outros em UTF-8. Al√©m disso, alguns conjuntos de dados podem apresentar problemas com as codifica√ß√µes mais comuns. √â importante lembrar que, para acessar o conte√∫do do arquivo CSV, √© necess√°rio utilizar o atributo ".content" do objeto retornado pela biblioteca Requests.

   ```py
   response_csv = requests.get(page['href'])
   encoding = chardet.detect(response_csv.content)['encoding']
   ```
Ap√≥s analisar a estrutura dos dados dispon√≠veis, observamos que os conjuntos de dados a partir de 2020 utilizam o ponto e v√≠rgula ";" como delimitador, enquanto os anteriores utilizam a v√≠rgula ",". Com base nessa observa√ß√£o, foi implementada uma condi√ß√£o para verificar a data do conjunto de dados. Utilizando o final do atributo "title" de cada dataset em uma condi√ß√£o, √© poss√≠vel identificar a qual data ele pertence e, assim, determinar qual delimitador deve ser utilizado durante o processamento.

   ```py
   if int(link["title"][-4:]) >= 2020:
       df3 = pd.read_csv(StringIO(response_csv.content.decode(encoding)), sep=';', encoding=encoding, low_memory=False)
   else:
       df3 = pd.read_csv(StringIO(response_csv.content.decode(encoding)), sep=',', encoding=encoding, low_memory=False)
   ```
   
Para armazenar os dados, foi criado um dataframe auxiliar utilizando a fun√ß√£o "read_csv" do Pandas. Dentro dessa fun√ß√£o, √© passado o conte√∫do do conjunto de dados em quest√£o. No entanto, √© necess√°rio utilizar a biblioteca "StringIO", conforme mostrado no c√≥digo acima. Essa biblioteca √© usada para tratar uma string (no caso, o conte√∫do do arquivo CSV) como se fosse um arquivo real, permitindo que o Pandas possa reconhec√™-lo corretamente.

Em seguida, o conte√∫do do arquivo CSV, armazenado no dataframe auxiliar, √© transferido para uma lista previamente criada. Essa abordagem visa melhorar o desempenho do Python durante o processamento dos dados.

   ```py
   dfs.append(df3)  # Adicionar o DataFrame intermedi√°rio √† lista
   ```
   
Por fim, o conte√∫do completo da lista √© adicionado ao dataframe principal, que ser√° utilizado em todo o processo de transforma√ß√£o.

   ```py
   df = pd.concat(dfs, ignore_index=True)
   ```

### Pr√©-processamento

Os dados disponibilizados pela Prefeitura cont√™m v√°rias quest√µes problem√°ticas, como a presen√ßa de 32 atributos e diversas categorias redundantes. Portanto, √© necess√°rio realizar um pr√©-processamento de acordo comos requisitos de neg√≥cio, j√° que sem realiza-lo, seria completamente invi√°vel realizar qualquer tipo de an√°lise. 

A seguir, ser√£o enumeradas as a√ß√µes realizadas para abordar essas quest√µes:

1. <b>Filtrar os dados do assunto</b>:
  
    O conjunto de dados abrange diversos assuntos al√©m da quest√£o animal. Portanto, os dados foram previamente filtrados, o que garante um tempo de processamento mais    eficiente nos pr√≥ximos passos, contribuindo para a agilidade e efic√°cia das etapas subsequentes.

    ```py
    df1 = df[df['Assunto'].str.contains('Animais', regex=False) | df['Tema'].str.contains(r'^Anim.*|^Pragas.*', regex=True)].reset_index(drop=True)
    ```

    √â importante ressaltar que foram utilizadas as colunas "Assunto" e "Tema" para filtragem dos dados. A escolha dessas colunas se deu pelo fato de que os conjuntos de dados mais recentes n√£o utilizam a coluna "Tema", apesar dela ser mais eficiente para esse prop√≥sito. Foi necess√°rio empregar uma express√£o regular na coluna "Assunto" para buscar qualquer ocorr√™ncia relacionada a animais ou pragas urbanas. Isso foi feito para garantir uma abrang√™ncia adequada na filtragem dos dados.
  

2. <b>Tratamento de atributos</b>:

    Ap√≥s verificar todos os 32 atributos, foi mantido no dataframe apenas 9 que ser√£o √∫teis na an√°lise. Sendo assim foram filtrados conforme o c√≥digo abaixo:

    ```py
    df = df[['Data de abertura', 'Tema', 'Assunto', 'Especifica√ß√£o do assunto', 'Servi√ßo', 'Bairro', 'Distrito'
         , 'Status da solicita√ß√£o', 'Data do parecer']]
    ```
    
    Ainda √© poss√≠vel reduzir a quantidade de colunas no dataframe, pois as colunas "Especifica√ß√£o do assunto" e "Servi√ßo" possuem a mesma finalidade. Essa redund√¢ncia ocorre devido aos conjuntos de dados mais recentes utilizarem apenas a coluna "Servi√ßo". Portanto, foi decidido utilizar a abordagem mais recente. No caso em que a coluna "Servi√ßo" est√° vazia (o que indica que os dados pertencem a conjuntos mais antigos), o seu valor ser√° preenchido com o conte√∫do da coluna "Especifica√ß√£o do assunto". Ap√≥s esse processo, a coluna "Especifica√ß√£o do assunto" ser√° removida do dataframe.
    
    ```py
    df1.loc[df1['Servi√ßo'].isnull(), 'Servi√ßo'] = df1.loc[df1['Servi√ßo'].isnull(), 'Especifica√ß√£o do assunto']
    df1 = df1.drop('Especifica√ß√£o do assunto', axis=1)
    ```
    
    N√£o h√° necessidade de utilizar "Bairro" e "Distrito" juntos, pois ambos podem indicar a localiza√ß√£o, apesar de haver essa divis√£o na cidade. Sendo assim, o "Bairro" ser√° utilizado para preencher os valores vazios em "Distrito". Al√©m disso, nos datasets de 2012 possuem c√≥digos de distrito ao inv√©s do nome, √© poss√≠vel saber qual distrito o c√≥digo pertence atrav√©s de uma tabela disponibilizada pela <a href="https://repositorio.seade.gov.br/dataset/codigos-nomes-dos-distritos-do-municipio-de-sao-paulo">Funda√ß√£o Seade</a>.
    
    ```py
    df1.loc[df1['Distrito'].isnull() & df1['Bairro'].notnull(), 'Distrito'] = df1.loc[df1['Distrito'].isnull() & df1['Bairro'].notnull(), 'Bairro']
    df1 = df1.drop('Bairro', axis=1)
    
    # Ap√≥s ler a tabela com os c√≥digos e coloca-lo em um dataframe
    df1['Distrito'] = df1['Distrito'].replace(distrito.set_index('Nr Distrito')['Nome Distrito'])
    ```
    
3. <b>Tratamento do nome de atributos</b>:

    Para facilitar a compreens√£o de cada tabela, foi decidido mudar o nome da coluna "Assunto" para "Tipo de servi√ßo", isso facilitar√° na compreens√£o dos dados, j√° que existe outro atributo como "Servi√ßo" que √© a descri√ß√£o do "Assunto".
    
    ```py
    df2 = df1.rename({'Assunto': 'Tipo de Servi√ßo'}, axis=1)
    ```
    
4. <b>Remover redund√¢ncias no "Tipo de Servi√ßo"</b>:

    Existe o "Tipo de Servi√ßo" chamado "Animais que transmitem doen√ßas ou risco √† sa√∫de", que abrange uma variedade de servi√ßos relacionados a problemas como pernilongos, ratos e outros. No entanto, h√° outros tipos de servi√ßo que poderiam se enquadrar nessa mesma categoria, mas est√£o separados, como "Animais/barata", "Animais/Aranha" e outros. Para solucionar isso, todos os "Tipos de Servi√ßo" que contenham a express√£o "Animais /" ser√£o convertidos para "Animais que transmitem doen√ßas ou risco √† sa√∫de". √â importante ressaltar que existem outros tipos de servi√ßo que tamb√©m possuem a express√£o "Animais /", mas n√£o se enquadram na categoria de "Animais que transmitem doen√ßas ou risco √† sa√∫de". Esses casos ser√£o ignorados no c√≥digo.
    
    ```py
    df2.loc[df2['Tipo de Servi√ßo'].str.contains('Animais[ |/]') & df2['Tipo de Servi√ßo']
        .str.match('^(?!.*(C√£o|Gato|Cavalo|silvestres|RGA|agressor|via))'), 'Tipo de Servi√ßo'
       ] = 'Animais que transmitem doen√ßas ou risco √† sa√∫de'
    ```
    

    Para aprimorar a forma como os tipos de servi√ßo est√£o sendo expressos, alguns deles passar√£o por um processo de simplifica√ß√£o. Por exemplo, o tipo de servi√ßo "Animais / C√£o" ser√° apresentado apenas como "C√£o" e "Vistoria / Animais" ser√° mostrado somente como "Vistoria". Para realizar essa modifica√ß√£o, o seguinte c√≥digo foi implementado:
    
    ```py
    df2['Tipo de Servi√ßo'] = df2['Tipo de Servi√ßo'].str.replace('Animais / ', '')
    df2['Tipo de Servi√ßo'] = df2['Tipo de Servi√ßo'].str.replace(' / Animais', '')
    ```


    O tipo de servi√ßo "Dengue/chikungunya/zika (mosquito Aedes aegypti)" √© classificado como um servi√ßo de vistoria, de acordo com a descri√ß√£o do servi√ßo. Para lidar com esse caso espec√≠fico, foi implementado o seguinte c√≥digo:

    ```py
    df2['Tipo de Servi√ßo'] = df2['Tipo de Servi√ßo'].str.replace('Dengue/chikungunya/zika (mosquito aedes aegypti)', 'Vistoria')
    ```
    
5. <b>Remover redund√¢ncias nos servi√ßos de "Animais que transmitem doen√ßas ou risco √† sa√∫de"</b>:

    Com o c√≥digo a seguir, √© poss√≠vel visualizar todos os servi√ßos classificados como "Animais que transmitem doen√ßas ou risco √† sa√∫de" e identificar poss√≠veis melhorias na forma como est√£o expressos:
    
    ```py
    df2.loc[df2['Tipo de Servi√ßo'] == 'Animais que transmitem doen√ßas ou risco √† sa√∫de', 'Servi√ßo'].drop_duplicates().sort_values()
    ```
    
    Ap√≥s an√°lise, foi identificado que existem diversos servi√ßos que est√£o separados, mas tratam do mesmo tema, como por exemplo: "Abelhas e Vespas", "Colmeia/Vespeiro instalado" e "Remo√ß√£o de Abelhas, Vespas ou Marimbondos". Todos eles est√£o relacionados ao tema de abelhas, vespas e marimbondos. Diante disso, foi decidido manter o servi√ßo "Remo√ß√£o de Abelhas, Vespas ou Marimbondos" e unificar os outros dois. Essa abordagem ser√° aplicada para outras inconsist√™ncias, conforme demonstrado no c√≥digo abaixo:
    
    ```py
    df3.loc[(df3['Servi√ßo'].str.contains('Pernilongo/Mosquito', regex=True)) | (df3['Servi√ßo'] == 'Reclama√ß√£o de Pernilongo'), 'Servi√ßo'] = 'Reclama√ß√£o de Pernilongos e Mosquitos'
    df3.loc[(df3['Servi√ßo'] == 'Abelhas e Vespas') | (df3['Servi√ßo'] == 'Colm√©ia/Vespeiro instalado'), 'Servi√ßo'] = 'Remo√ß√£o de Abelhas, Vespas ou Marimbondos'
    df3.loc[df3['Servi√ßo'].str.contains('Escorpi√£o', regex=True), 'Servi√ßo'] = 'Escorpi√µes'
    df3.loc[df3['Servi√ßo'] == 'Reclama√ß√£o de Escorpi√£o', 'Servi√ßo'] = 'Reclama√ß√£o de Escorpi√µes'
    df3.loc[df3['Servi√ßo'] == 'Ocorr√™ncias com morcego', 'Servi√ßo'] = 'Reclama√ß√£o de Morcegos'
    ```
    
    Existem alguns servi√ßos que cont√™m palavras desnecess√°rias, as quais ser√£o removidas para fins de padroniza√ß√£o. Por exemplo, t√™m registros como "Pernilongo/Mosquito - Solicitar vistoria em local infestado" e "Pombos - Solicitar vistoria em local infestado", enquanto j√° existe "Reclama√ß√£o de mosquitos" e "Reclama√ß√£o de pombos", que s√£o mais adequados para descrever os servi√ßos oferecidos pela Prefeitura. Para solucionar essa quest√£o, foi desenvolvido um c√≥digo para substituir todos os servi√ßos que possuem um h√≠fen ("-") por "Reclama√ß√£o de...", assim padronizando a nomenclatura dos servi√ßos.
    
    ```py
    df3.loc[df3['Tipo de Servi√ßo'] == 'Animais que transmitem doen√ßas ou risco √† sa√∫de', 'Servi√ßo'] = df3.loc[df3[
        'Tipo de Servi√ßo'] == 'Animais que transmitem doen√ßas ou risco √† sa√∫de', 'Servi√ßo'].str.replace(r' -.*', '', regex=True)
        
    df3.loc[df3['Servi√ßo'].str.split().str.len() == 1, 'Servi√ßo'] = 'Reclama√ß√£o de ' + df3['Servi√ßo']
    ```
    
6. <b>Remover redund√¢ncias nos servi√ßos que n√£o s√£o "Animais que transmitem doen√ßas ou risco √† sa√∫de"</b>:
    
    Diferente da √∫ltima etapa, esta ser√° para padronizar os servi√ßos que n√£o s√£o "Animais que transmitem doen√ßas ou risco √† sa√∫de", portanto o seguinte c√≥digo foi executado:

    ```py
    pd.set_option('display.max_colwidth', None) # Poder ler todos os textos
    df3.loc[df3['Tipo de Servi√ßo'] != 'Animais que transmitem doen√ßas ou risco √† sa√∫de', 'Servi√ßo'].drop_duplicates().sort_values()
    ```
    
    Foram identificados alguns caracteres incorretos, como espa√ßos em branco ou pontos de interroga√ß√£o que foram inseridos por engano. Para corrigir essa quest√£o, o seguinte c√≥digo foi executado:
    
    ```py
    df3['Servi√ßo'] = df3['Servi√ßo'].str.replace('?', '-')
    df3['Servi√ßo'] = df3['Servi√ßo'].str.replace('‚Äì', '-')
    df3['Servi√ßo'] = df3['Servi√ßo'].str.replace('Invadiu o local ', 'Invadiu o local')
    ```
    
    Durante o processo de tratamento dos caracteres incoerentes, foi realizada uma busca por redund√¢ncias no conjunto de dados. Foram identificadas tr√™s categorias relacionadas a animais acidentados ou atropelados, todas contendo a mesma informa√ß√£o. Para padronizar esses registros, optou-se por alterar todas as ocorr√™ncias para "Atropelado ou Acidentado vivo e sem propriet√°rio".

    Outra redund√¢ncia encontrada foi em rela√ß√£o √†s categorias que tratam das condi√ß√µes de cria√ß√£o. As categorias "Condi√ß√µes de cria√ß√£o", "Denunciar condi√ß√µes inadequadas de cria√ß√£o" e "Condi√ß√µes de cria√ß√£o / maus tratos" representam o mesmo problema. Foi decidido manter a categoria "Condi√ß√µes de cria√ß√£o / maus tratos" por ser mais eficiente na express√£o da situa√ß√£o.

    A terceira redund√¢ncia diz respeito √† remo√ß√£o de animais mortos em vias p√∫blicas. A categoria "Remo√ß√£o de animal morto em via p√∫blica" apresenta varia√ß√µes, como palavras no plural ou singular, ou at√© mesmo acr√©scimos de palavras que n√£o fazem diferen√ßa no resultado final.

    A seguir, ser√° apresentado o c√≥digo respons√°vel por realizar essas altera√ß√µes:
    
    ```py
    df3.loc[df3['Servi√ßo'].str.contains('Atropelado') | df3['Servi√ßo'].str.contains('Acidentado'), 'Servi√ßo'
           ] = 'Atropelado ou Acidentado vivo e sem propriet√°rio'
    df3.loc[df3['Servi√ßo'].str.match('.*ondi√ß√µes'), 'Servi√ßo'
       ] = 'Condi√ß√µes de cria√ß√£o / maus tratos'
    df3.loc[df3['Servi√ßo'].str.match('.*morto em via.*'), 'Servi√ßo'
       ] = 'Remo√ß√£o de animal morto em via p√∫blica'
    ```
    
    Com a execu√ß√£o desses c√≥digos, as redund√¢ncias foram eliminadas e as categorias foram padronizadas, resultando em dados mais consistentes.
    
    Durante a an√°lise dos servi√ßos, identificou-se que alguns deles n√£o est√£o descritos de forma clara, como √© o caso de "Solto em via p√∫blica". Para melhorar a compreens√£o desses servi√ßos, foi desenvolvido um c√≥digo que utiliza o "Tipo de Servi√ßo" para complementar o texto. Dessa forma, o servi√ßo ser√° apresentado de maneira mais explicativa, como por exemplo "C√£o Solto em via p√∫blica" no caso mencionado anteriormente.

    A seguir, √© apresentado o c√≥digo utilizado para realizar essa melhoria na descri√ß√£o dos servi√ßos:
    
    ```py
    condicoes = (df3['Servi√ßo'] == 'Em parques') | (df3['Servi√ßo'] == 'Invadiu o local') | (df3['Servi√ßo'] == 'Solto em via p√∫blica')
    df3.loc[condicoes, 'Servi√ßo'] = df3.loc[condicoes, 'Tipo de Servi√ßo'].str.cat(df3.loc[condicoes, 'Servi√ßo'], sep=' ')
    
    condicoes = (df3['Servi√ßo'] == 'Diversas ocorr√™ncias') | (df3['Servi√ßo'] == 'Ocorr√™ncias rotineiras')
    df3.loc[condicoes, 'Servi√ßo'] = df3.loc[condicoes, 'Tipo de Servi√ßo'].str.cat(df3.loc[condicoes, 'Servi√ßo'], sep=' - ')
    ```
    
    √â importante observar que, durante o processo, foram utilizados dois separadores distintos para diferentes casos. No primeiro caso, onde o objetivo era formar uma frase cont√≠nua, foi utilizado um √∫nico espa√ßo como separador. Isso contribui para a legibilidade e fluidez do texto, seguindo as conven√ß√µes gramaticais de espa√ßamento entre palavras.

    No segundo caso, em que os termos "diversos casos" e "Ocorr√™ncias rotineiras" atuam como agregadores, optou-se pelo uso de um h√≠fen como separador. Essa escolha se baseia em uma considera√ß√£o gramatical, onde o h√≠fen √© utilizado para unir termos que formam uma unidade sem√¢ntica e representam uma √∫nica ideia.

    Dessa forma, ao utilizar o h√≠fen como separador, est√° sendo indicado que "diversos casos" e "Ocorr√™ncias rotineiras" s√£o elementos que est√£o relacionados e constituem um conjunto coeso.

7. <b>Capitaliza√ß√£o dos Servi√ßos (Capitalize)</b>:


    Diversos servi√ßos apresentam inconsist√™ncias na capitaliza√ß√£o das palavras, com algumas iniciando em mai√∫sculas e outras n√£o. Al√©m disso, h√° redund√¢ncias devido √† etapa 5. Para corrigir esses problemas, √© poss√≠vel utilizar o processo de capitalize. No entanto, √© importante observar algumas regras, uma vez que alguns servi√ßos utilizam "-" e "/" para separar termos, e tamb√©m cont√™m nomes pr√≥prios que requerem todas as palavras em mai√∫sculas. Devido a essas particularidades, n√£o foi poss√≠vel utilizar diretamente o m√©todo <code>capitalize()</code> do Python. Portanto, foi necess√°rio criar a seguinte fun√ß√£o e aplic√°-la:

    ```py
    # Fun√ß√£o para realizar o capitalize com a regra
    def capitalize(servico):
        # Descobrir o sinal que a frase usa
        sinal = re.findall(r" - | / ", servico)
        
        if sinal:
            # Dividindo a frase em duas partes: antes e depois do tra√ßo ou da barra
            partes = re.split(sinal[0], servico)
            
            # Realizando o capitalize na primeira parte (antes do tra√ßo)
            parte1 = partes[0].capitalize()
    
            # Realizando o capitalize na segunda parte (depois do tra√ßo)
            parte2 = partes[1].capitalize()
            
            return "".join([parte1, sinal[0], parte2])
        else:
            return servico.capitalize()

    # Aplica√ß√£o da fun√ß√£o
    df3['Servi√ßo'] = df3['Servi√ßo'].apply(lambda x: capitalize(x) if not re.search(r'RGA|CMCA', x) else x)
    ```

    A fun√ß√£o recebe o par√¢metro "servi√ßo" e realiza uma busca do "-" ou da "/" com uma express√£o regex. Caso seja encontrado, o m√©todo "split" √© aplicado para dividir o servi√ßo com base no sinal encontrado. Em seguida, o m√©todo capitalize √© executado em cada uma das partes resultantes. Por fim, o m√©todo join √© utilizado para concatenar as duas partes capitalizadas, inserindo o sinal entre elas.

    O m√©todo apply do Pandas foi utilizado na coluna "Servi√ßo", invocando a fun√ß√£o por meio de uma fun√ß√£o lambda. A fun√ß√£o lambda s√≥ aplicar√° a fun√ß√£o se a coluna n√£o contiver nenhuma sigla, uma vez que siglas n√£o devem ser modificadas.
  
     
9. <b>Formata√ß√£o de datas</b>:

    Durante o processo de extra√ß√£o dos datasets, foi identificado que eles possuem tr√™s formatos diferentes para representar as datas. Esses formatos incluem apenas a data no formato "yyyy-mm-dd", uma combina√ß√£o de data e hora no formato datetime com c√≥digo e outra representa√ß√£o apenas como datetime.

    Com o objetivo de padronizar a representa√ß√£o das datas e facilitar a manipula√ß√£o dos dados, foi tomada a decis√£o de realizar um processo de extra√ß√£o para manter somente o formato "yyyy-mm-dd" como data. Isso permitir√° uma uniformidade nos registros e facilitar√° a an√°lise e compara√ß√£o dos dados ao longo do tempo.

    Ao adotar essa abordagem, ser√° poss√≠vel garantir consist√™ncia e coer√™ncia nos datasets, tornando-os mais acess√≠veis e compat√≠veis com as opera√ß√µes de processamento e an√°lise que ser√£o realizadas posteriormente no Power BI.
    
    ```py
    df4['Data de abertura'] = df4['Data de abertura'].str.slice(0,10)
    
    df4.loc[df4['Data do parecer'].notnull(), 'Data do parecer'] = df4.loc[
    df4['Data do parecer'].notnull(), 'Data do parecer'].str.slice(0,10)
    ```
    
    Por ter valores nulos (no caso os servi√ßos que ainda n√£o foram atendidos) a extra√ß√£o de data foi realizada apenas para os valores n√£o nulos, conforme o c√≥digo anterior.
    
Ap√≥s a conclus√£o desse processo, torna-se evidente uma not√°vel melhoria na consist√™ncia dos dados. Al√©m disso, houve uma significativa redu√ß√£o no tamanho do conjunto de dados e na quantidade de registros. Essa redu√ß√£o √© de extrema import√¢ncia, uma vez que um volume excessivo de registros poderia dificultar ou at√© mesmo inviabilizar a an√°lise dos dados.

Portanto, com o processo de redu√ß√£o e otimiza√ß√£o finalizado, os dados agora est√£o prontos para serem explorados de forma mais eficiente e eficaz, possibilitando uma an√°lise mais robusta e precisa.


### Armazenamento dos Dados

Para que os dados possam ser analisados no Power BI, √© necess√°rio armazen√°-los em um local apropriado. Neste caso, optamos por salvar os dados em formato Parquet compactado. Essa escolha foi baseada em um estudo pr√©vio realizado com os mesmos dados em formato CSV, no qual foi constatado que o Parquet ocuparia 80.000 KB a menos em espa√ßo de armazenamento em compara√ß√£o ao CSV. Al√©m disso, sem o pr√©-processamento realizado posteriormente, o tamanho ocupado em disco seria superior a 1 GB.

Portanto, para salvar os dados no formato Parquet compactado com compress√£o Gzip, foi utilizado o seguinte c√≥digo:

  ```py
  df4.to_parquet('sp156_all_time.gzip',
              compression='gzip',
              index=False)
  ```


### Considera√ß√µes Finais do Processamento

Embora tenha obtido sucesso em todo o processo de garantir a inclus√£o dos distritos na an√°lise, √© importante ressaltar que os distritos de den√∫ncias anteriores a 2015 n√£o devem ser utilizados. Isso ocorre porque os dados fornecidos pela Prefeitura de S√£o Paulo para esses distritos n√£o est√£o coerentes com os respectivos logradouros ou com os c√≥digos de distrito da Funda√ß√£o Seade que foram utilizados para a descri√ß√£o. Portanto, recomenda-se excluir os dados dos distritos de den√∫ncias anteriores a 2015 para evitar inconsist√™ncias na an√°lise.
    
    
<!-- LICENSE -->
## License

Distributed under the BSD 2-Clause License. See `LICENSE.txt` for more information.



<!-- CONTACT -->
## Contact

Demik Freitas - [Linkedin](https://www.linkedin.com/in/demik-freitas/) - demik.freitast2d18@gmail.com

Project Link: [https://github.com/DemikFR/Analise-Controle-Zoonoses-SP156](https://github.com/DemikFR/Analise-Controle-Zoonoses-SP156)



<!-- MARKDOWN LINKS & IMAGES -->
<!-- https://www.markdownguide.org/basic-syntax/#reference-style-links -->
[Python.py]: https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54
[Python-url]: https://www.python.org/
[Power-BI.pbix]: https://img.shields.io/badge/power_bi-F2C811?style=for-the-badge&logo=powerbi&logoColor=black
[Power-BI-url]: https://www.python.org/
